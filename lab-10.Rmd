---
title: "Lab 9 - Modeling professor attractiveness and course evaluations"
author: "Cat Seitz"
date: "02.28.2023"
output: github_document
---

### Load packages and data

```{r load-packages, message=FALSE}
library(tidyverse) 
library(tidymodels)
library(openintro)
library(broom)
```

### Exercise 1

```{r distribution-score}

evals<-evals

ggplot(evals, aes(x=score))+
  geom_histogram(binwidth=0.1)

```

The distribution is negatively skewed. Students seem to rate most professors relatively highly. I would expect this for a few reasons: 1) they are professors - typically tenured or tenure-track at a university - so I would expect them to have some experience and be decent, 2) the students are paying tuition to be there so they wouldn't necessarily want to admit that they're not getting great instruction, 3) these scores are the average across many students' evaluations so it's unlikely to get a consensus bad review. 


### Exercise 2

```{r vis-score-beauty}

ggplot(evals, aes(x = bty_avg, y=score))+
  geom_point()+
  stat_smooth(method="lm", se=F)+
  #annotate("text", x=2.8, y=8, label=(paste0("slope==", coef(lm(evals$score~evals$bty_avg))[2])), parse=TRUE)+
  labs(title="Relationship between Score and Beauty", y="Evaluation Score", x="Average Beauty Rating")

```

Evaluation score and average beauty rating seem to be correlated; so typically, higher beauty ratings also get higher evaluation scores. 


### Exercise 3


```{r jitter-score-beauty}

ggplot(evals, aes(y = score, x=bty_avg))+
  geom_jitter()+
  stat_smooth(method="lm")+
  labs(title="Relationship between Score and Beauty", y="Evaluation Score", x="Average Beauty Rating")

```

Jitter "adds a small amount of random variation to the location of each point." This new plot handles overplotting, so now all of the data points are pretty much in view. 


### Exercise 4

We are trying to understand variations in evaluation score based on beauty rating. 

```{r fit-linear-model}

linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg, data = evals) %>%
  tidy()

```

Model: (Evaluation Score) = 3.88 + 0.067(Beauty Rating)

This model was significant, so beauty ratings significantly predicted evaluation scores of professors. 

### Exercise 5

I had already plotted with the regression line before being asked to do so, so here it is again, but in orange. 

```{r score-beauty-line}

ggplot(evals, aes(y = score, x=bty_avg))+
  geom_jitter()+
  stat_smooth(method="lm", color= "orange", se=FALSE)+
  labs(title="Relationship between Score and Beauty", y="Evaluation Score", x="Average Beauty Rating")

```

### Exercise 6

The higher the average beauty ratings professors receive, the higher evaluation scores they are given by students. 


### Exercise 7 

The intercept indicates the evaluation score a professor would receive if their beauty rating was 0. In this context, this makes sense because professors can still be evaluated if they are extremely unattractive.

### Exercise 8 

Since R-squared is the same as the slope of our regression line, so it is .067. This suggests that 6.7% of the variation in evaluation scores is accounted for by beauty ratings, which may not seem like a lot but it is more than we would like considering beauty shouldn't play a role in the how well a professor can teach. 

### Exercise 9 

Here, I just plotted the evaluation scores based on gender to see which gender has higher scores on average. 

```{r plot-gender}

ggplot(evals, aes(y = score, x=gender))+
  geom_point(alpha=.3)+
  stat_summary(aes(y=score, group=1), fun=mean, color="orange", geom="line", group=1)+
  labs(title="Relationship between Score and Gender", y="Evaluation Score", x="Gender")

```

```{r fit-model-categorical}

linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ gender, data = evals) %>%
  tidy()

```

Model: (Evaluation Score)=4.09 + 0.14(gender)

The slope indicates that males typically have higher evaluation scores by 0.14 points. The intercept is the average evaluation score of the female professors. 


### Exercise 10 

What is the equation of the line corresponding to male professors? What is it for female professors?

### Exercise 11

```{r fit-model-mrank}

linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ rank, data = evals) %>%
  tidy()

```

Model: (Evaluation Score)= 4.28 - .13(tenure track professors) - .15(tenured professors) <- this seems off??

Teaching professors are expected, on average, to have an evaluation score of 4.28. Tenure track professors are expected, on average, to have scores .13 points less than teaching professors, and tenured professors are expected, on average, to have scores .15 points less than teaching professors. 


### Exercise 12

```{r rank-relevel}

evals<-evals %>%
  mutate(rank_relevel = 
           case_when(rank=="tenure track" ~"A",
                     rank=="tenured"~"B",
                     rank=="teaching"~"C"))

```


### Exercise 13

```{r fit-model-mrank-relevel}

linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ rank_relevel, data = evals) %>%
  tidy()

```

Model: (Evaluation Score)

Fit a new linear model called m_rank_relevel to predict average professor evaluation score based on rank_relevel of the professor. This is the new (releveled) variable you created in Exercise 13. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the R2 of the model.

### Exercise 14

Create another new variable called tenure_eligible that labels "teaching" faculty as "no" and labels "tenure track" and "tenured" faculty as "yes".

### Exercise 15

Fit a new linear model called m_tenure_eligible to predict average professor evaluation score based on tenure_eligibleness of the professor. This is the new (regrouped) variable you created in Exercise 15. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the R2 of the model.







































